# coding=utf-8
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

# Prediction Metrics
# This module provides a set of prediction accuracy metrics. It is a support
# module for several machine learning algorithms that require metrics to
# validate their models. A typical function will take a set of "prediction" and
# "observation" values to calculate the desired metric, unless noted otherwise.
# Grouping is supported by all of these functions (except confusion matrix).

# Please refer to the pred_metrics.sql_in file for the documentation

from utilities.utilities import unique_string
import plpy

# Mean Absolute Error.
def mean_abs_error(
    schema_madlib, table_in, table_out, prediction_col, observed_col,
    grouping_cols=None):
    sql_st1 = """
        CREATE TABLE {table_out} AS
        SELECT
             """.format(**locals())
    sql_st2= ""
    sql_st3= """ AVG(ABS({prediction_col}- {observed_col})) AS mean_abs_error
        FROM {table_in} """.format(**locals())
    sql_st4= ""
    if grouping_cols:
        sql_st2= """{grouping_cols}, """.format(**locals())
        sql_st4= """ GROUP BY {grouping_cols}""".format(**locals())
    sql_st = sql_st1+sql_st2+sql_st3+sql_st4
    plpy.execute(sql_st)

# Mean Absolute Percentage Error.
def mean_abs_perc_error(
    schema_madlib, table_in, table_out, prediction_col, observed_col,
    grouping_cols=None):
    sql_st1 = """
        CREATE TABLE {table_out} AS
        SELECT
             """.format(**locals())
    sql_st2= ""
    sql_st3= """ AVG(ABS({prediction_col}- {observed_col}) /
        NULLIF({observed_col},0)) AS mean_abs_perc_error
        FROM {table_in} """.format(**locals())
    sql_st4= ""
    if grouping_cols:
        sql_st2= """{grouping_cols}, """.format(**locals())
        sql_st4= """ GROUP BY {grouping_cols}""".format(**locals())
    sql_st = sql_st1+sql_st2+sql_st3+sql_st4
    plpy.execute(sql_st)

# Mean Percentage Error.
def mean_perc_error(
	schema_madlib, table_in, table_out, prediction_col, observed_col,
    grouping_cols=None):
    sql_st1 = """
        CREATE TABLE {table_out} AS
        SELECT
             """.format(**locals())
    sql_st2= ""
    sql_st3= """ AVG(({prediction_col}- {observed_col}) /
        NULLIF({observed_col},0)) AS mean_perc_error
        FROM {table_in} """.format(**locals())
    sql_st4= ""
    if grouping_cols:
        sql_st2= """{grouping_cols}, """.format(**locals())
        sql_st4= """ GROUP BY {grouping_cols}""".format(**locals())
    sql_st = sql_st1+sql_st2+sql_st3+sql_st4
    plpy.execute(sql_st)

# Mean Squared Error.
def mean_squared_error(
	schema_madlib, table_in, table_out, prediction_col, observed_col,
    grouping_cols=None):
    sql_st1 = """
        CREATE TABLE {table_out} AS
        SELECT
             """.format(**locals())
    sql_st2= ""
    sql_st3= """ AVG(({prediction_col}- {observed_col})^2) AS mean_squared_error
     FROM {table_in} """.format(**locals())
    sql_st4= ""
    if grouping_cols:
        sql_st2= """ {grouping_cols}, """.format(**locals())
        sql_st4= """ GROUP BY {grouping_cols}""".format(**locals())
    sql_st = sql_st1+sql_st2+sql_st3+sql_st4
    plpy.execute(sql_st)

# R-squared.
def __r2_score(
	schema_madlib, table_in, table_out, prediction_col, observed_col):


    sql_st = """
        CREATE TABLE {table_out} AS
            SELECT 1 - ssres/sstot AS r2_score FROM (
                SELECT sum(({prediction_col} - {observed_col})^2) AS ssres,
                sum(( {observed_col} - (
                    SELECT SUM({observed_col})/count(*) AS mean
                    FROM {table_in}))^2
                ) AS sstot FROM {table_in}
            ) x
        """.format(**locals())
    plpy.execute(sql_st)

def r2_score(
	schema_madlib, table_in, table_out, prediction_col, observed_col,
    grouping_cols):

    if grouping_cols is None:
        __r2_score(schema_madlib, table_in, table_out, prediction_col
            , observed_col)
        return

    sql_st = """

        CREATE TABLE {table_out} AS
            SELECT {grouping_cols}, 1 - ssres/sstot AS r2_score FROM (
                SELECT {grouping_cols}, sum ( ({observed_col}- mean)^2) as sstot
                    , sum(({prediction_col} - {observed_col})^2) AS ssres
                FROM(
                    SELECT {grouping_cols}, {prediction_col}, {observed_col},
                        avg({observed_col}) OVER (PARTITION BY {grouping_cols})
                            as mean
                    FROM {table_in}
                ) x GROUP BY {grouping_cols}
            ) y
        """.format(**locals())
    plpy.execute(sql_st)

# Adjusted R-squared.
def __adjusted_r2_score(
	schema_madlib, table_in, table_out, prediction_col, observed_col,
    num_predictors, training_size):

    sql_st = """
        CREATE TABLE {table_out} AS
            SELECT 1-(((1- r2_score)*({training_size}-1)) /
                ({training_size}- {num_predictors}-1)) AS adjusted_r2_score
            FROM (
                SELECT 1 - ssres/sstot AS r2_score FROM (
                  SELECT sum(({prediction_col} - {observed_col})^2) AS ssres,
                    sum(( {observed_col} - (
                        SELECT AVG({observed_col}) AS mean
                        FROM {table_in}))^2
                    ) AS sstot FROM {table_in}
                ) x
            )y
        """.format(**locals())
    plpy.execute(sql_st)

def adjusted_r2_score(
	schema_madlib, table_in, table_out, prediction_col, observed_col,
    num_predictors, training_size, grouping_cols):

    if grouping_cols is None:
        __adjusted_r2_score( schema_madlib, table_in, table_out, prediction_col,
            observed_col, num_predictors, training_size)
        return

    sql_st = """
        CREATE TABLE {table_out} AS
        SELECT {grouping_cols}, 1-(((1- r2_score )*({training_size} -1)) /
            ({training_size} - {num_predictors}-1)) AS adjusted_r2_score
        FROM(
            SELECT {grouping_cols}, 1 - ssres/sstot AS r2_score FROM (
              SELECT {grouping_cols}, sum ( ({observed_col}- mean)^2) as sstot
                  , sum(({prediction_col} - {observed_col})^2) AS ssres
              FROM(
                  SELECT {grouping_cols}, {prediction_col}, {observed_col},
                      avg({observed_col}) OVER (PARTITION BY {grouping_cols})
                          as mean
                  FROM {table_in}
              ) x GROUP BY {grouping_cols}
          ) y
        )z
        """.format(**locals())
    plpy.execute(sql_st)

# Binary classification metrics.
def __binary_classifier(
	schema_madlib, table_in, table_out, prediction_col, observed_col):

    sql_st = """
    CREATE TABLE {table_out} AS SELECT *,
      tp*1.0/NULLIF(tp+fn,0) AS tpr,
      tn*1.0/NULLIF(fp+tn,0) AS tnr,
      tp*1.0/NULLIF(tp+fp,0) AS ppv,
      tn*1.0/NULLIF(tn+fn,0) AS npv,
      fp*1.0/NULLIF(fp+tn,0) AS fpr,
      fp*1.0/NULLIF(fp+tp,0) AS fdr,
      fn*1.0/NULLIF(fn+tp,0) AS fnr,
      (tp+tn)*1.0/NULLIF(tp+tn+fp+fn,0) AS acc,
      2.0*tp/NULLIF(2*tp+fp+fn,0) AS f1
    FROM (
      SELECT threshold,
             sum(t) OVER (ORDER BY threshold DESC) AS tp,
             sum(f) OVER (ORDER BY threshold DESC) AS fp,
             sum(t) OVER () - sum(t) OVER (ORDER BY threshold DESC) AS fn,
             sum(f) OVER () - sum(f) OVER (ORDER BY threshold DESC) AS tn
        FROM (
          SELECT {prediction_col} AS threshold,sum({observed_col}) AS t,
                 count(*)-sum({observed_col}) AS f
            FROM {table_in}
          GROUP BY (threshold)
        ) x
    ) y
    ORDER BY threshold
    """.format(**locals())
    plpy.execute(sql_st)

def binary_classifier(
	schema_madlib, table_in, table_out, prediction_col, observed_col,
    grouping_cols):

    if grouping_cols is None:
        __binary_classifier(
        	schema_madlib, table_in, table_out, prediction_col, observed_col)
        return

    sql_st = """
    CREATE TABLE {table_out} AS SELECT *,
        tp*1.0/NULLIF(tp+fn,0) AS tpr,
        tn*1.0/NULLIF(fp+tn,0) AS tnr,
        tp*1.0/NULLIF(tp+fp,0) AS ppv,
        tn*1.0/NULLIF(tn+fn,0) AS npv,
        fp*1.0/NULLIF(fp+tn,0) AS fpr,
        fp*1.0/NULLIF(fp+tp,0) AS fdr,
        fn*1.0/NULLIF(fn+tp,0) AS fnr,
        (tp+tn)*1.0/NULLIF(tp+tn+fp+fn,0) AS acc,
        2.0*tp/NULLIF(2*tp+fp+fn,0) AS f1
    FROM (
        SELECT {grouping_cols},threshold,
             sum(t) OVER (PARTITION BY {grouping_cols}
                          ORDER BY threshold DESC) AS tp,
             sum(f) OVER (PARTITION BY {grouping_cols}
                          ORDER BY threshold DESC) AS fp,
             sum(t) OVER (PARTITION BY {grouping_cols})
               - sum(t) OVER (PARTITION BY {grouping_cols}
                              ORDER BY threshold DESC) AS fn,
             sum(f) OVER (PARTITION BY {grouping_cols})
               - sum(f) OVER (PARTITION BY {grouping_cols}
                              ORDER BY threshold DESC) AS tn
        FROM (
          SELECT {grouping_cols},
                 {prediction_col} AS threshold,
                 sum({observed_col}) AS t,
                 count(*)- sum({observed_col}) AS f
            FROM {table_in}
          GROUP BY {grouping_cols}, threshold
        ) x
    ) y
    """.format(**locals())
    plpy.execute(sql_st)

# Area under the ROC curve.
def __area_under_roc (
    schema_madlib, table_in, table_out, prediction_col, observed_col):

    sql_st = """
    CREATE TABLE {table_out} AS
    SELECT sum((tpr+prev_tpr)*(fpr-prev_fpr)*0.5) AS area_under_roc
    FROM (
      SELECT tpr, fpr,
             coalesce(lag(tpr) OVER (ORDER BY threshold DESC),0) AS prev_tpr,
             coalesce(lag(fpr) OVER (ORDER BY threshold DESC),0) AS prev_fpr
      FROM(
        SELECT threshold,
               sum(t) OVER (ORDER BY threshold DESC)
                 *1.0/NULLIF(sum(t) OVER (),0) AS tpr,
               sum(f) OVER (ORDER BY threshold DESC)
                 *1.0/NULLIF(sum(f) OVER (),0) AS fpr
        FROM (
          SELECT {prediction_col} AS threshold,sum({observed_col}) AS t,
                 count(*)-sum({observed_col}) AS f
          FROM {table_in}
          GROUP BY (threshold)
        ) x
      ) y
    ) z;
    """.format(**locals())
    plpy.execute(sql_st)

def area_under_roc (
    schema_madlib, table_in, table_out, prediction_col, observed_col,
    grouping_cols):

    if grouping_cols is None:
        __area_under_roc(
        	schema_madlib, table_in, table_out, prediction_col, observed_col)
        return

    sql_st = """
    CREATE TABLE {table_out} AS
    SELECT {grouping_cols}, sum((tpr+prev_tpr)*(fpr-prev_fpr)*0.5) AS area_under_roc
    FROM (
      SELECT {grouping_cols}, tpr, fpr,
             coalesce(lag(tpr) OVER (PARTITION BY {grouping_cols}
                                     ORDER BY threshold DESC),0) AS prev_tpr,
             coalesce(lag(fpr) OVER (PARTITION BY {grouping_cols}
                                     ORDER BY threshold DESC),0) AS prev_fpr
      FROM(
        SELECT {grouping_cols}, threshold,
               sum(t) OVER (PARTITION BY {grouping_cols} ORDER BY threshold DESC)
                    *1.0/NULLIF(sum(t) OVER (PARTITION BY {grouping_cols}),0)
                    AS tpr,
               sum(f) OVER (PARTITION BY {grouping_cols} ORDER BY threshold DESC)
                    *1.0/NULLIF(sum(f) OVER (PARTITION BY {grouping_cols}),0)
                    AS fpr
        FROM (
          SELECT {grouping_cols},
                 {prediction_col} AS threshold,sum({observed_col}) AS t,
                 count(*)-sum({observed_col}) AS f
          FROM {table_in}
          GROUP BY {grouping_cols},threshold
        ) x
      ) y
    ) z
    GROUP BY {grouping_cols}
    """.format(**locals())
    plpy.execute(sql_st)

# Confusion Matrix for a multi-class classifier.
def confusion_matrix(
    schema_madlib, table_in, table_out, prediction_col, observed_col):
    sql_st = """
    CREATE TABLE {table_out} AS
      SELECT class,
             array_agg(cnt ORDER BY pred) AS confusion_arr
      FROM (
            SELECT class,
                   pred,
                   sum(cnt) AS cnt
            FROM (
                  SELECT {observed_col} AS class,
                         {prediction_col} AS pred,
                         count(*) AS cnt
                  FROM {table_in}
                  GROUP BY class, pred
                  UNION
                  SELECT a, b, 0
                  FROM (
                        SELECT {observed_col} AS a
                        FROM {table_in}
                        GROUP BY a
                        UNION
                        SELECT {prediction_col}
                        FROM {table_in}
                        GROUP BY ({prediction_col})
                  ) r,
                  ( SELECT {observed_col} AS b
                    FROM {table_in}
                    GROUP BY b
                    UNION
                    SELECT {prediction_col}
                    FROM {table_in}
                    GROUP BY ({prediction_col})
                  ) s
            ) y
            GROUP BY class, pred
      ) x
      GROUP BY class
    """.format(**locals())
    plpy.execute(sql_st)
