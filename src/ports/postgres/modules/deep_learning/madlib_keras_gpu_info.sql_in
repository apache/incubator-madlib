/* ----------------------------------------------------------------------- *//**
 *
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 *
 *
 * @file madlib_keras_gpu_info.sql_in
 *
 * @brief SQL functions for GPU configuration.
 * @date Nov 2019
 *
 *
 *//* ----------------------------------------------------------------------- */

m4_include(`SQLCommon.m4')

/**
@addtogroup grp_gpu_configuration

@brief Utility function to report number and type of GPUs on the database cluster.

\warning <em> This MADlib method is still in early stage development.
Interface and implementation are subject to change. </em>

<div class="toc"><b>Contents</b><ul>
<li class="level1"><a href="#get_gpu_config">GPU Configuration</a></li>
<li class="level1"><a href="#example">Examples</a></li>
<li class="level1"><a href="#references">References</a></li>
<li class="level1"><a href="#related">Related Topics</a></li>
</ul></div>

This utility function reports the number and type of GPUs
attached to hosts on the database cluster.
This can be useful when determining which segments to use for
training deep neural nets.  For example, for economic reasons
you may wish to set up a heterogeneous clusters with GPUs only
on some of the hosts, not all of them. This utility
can help you identify where the GPUS are and direct the compute
to those locations only in subsequent training and evaluation steps.

@anchor get_gpu_config
@par GPU Confuguration

<pre class="syntax">
gpu_configuration(
	source
	)
</pre>
\b Arguments
<dl class="arglist">
  <dt>source (optional)</dt>
  <dd>TEXT, default: 'tensorflow'. Source for determining GPU configuration.
  Using 'tensorflow' returns a description based on what TensorFlow reports.
  Using 'nvidia' returns a description based on what the Nvidia Systems
  Management Interface (nvidia-smi) reports [1].  Note that MADlib and Keras will use the
  TensorFlow information; the lower level nvidia-smi info is provided for convenience.
  </dd>
</dl>

<b>Output</b>
<br>
    The output contains the following:
    <table class="output">
      <tr>
        <th>hostname</th>
        <td>TEXT. Name of the host machine in the cluster.
        Does not include master or mirrors.  For PostgreSQL
        this will always return 'localhost'.
        </td>
      </tr>
      <tr>
        <th>gpu_info</th>
        <td>TEXT. String reported by TensorFlow or nvidia-smi.
        The formats are different and shown in the examples below.
        </td>
      </tr>
    </table>
</br>


@anchor example
@par Examples

-# Get GPU configuration as per TensorFlow:
<pre class="example">
SELECT * FROM madlib.gpu_configuration();
</pre>
<pre class="result">
 hostname |                                        gpu_descr
----------+------------------------------------------------------------------------------------------
 phoenix0 | device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0
 phoenix0 | device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:05.0, compute capability: 6.0
 phoenix0 | device: 2, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:06.0, compute capability: 6.0
 phoenix0 | device: 3, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:07.0, compute capability: 6.0
 phoenix1 | device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0
 phoenix1 | device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:05.0, compute capability: 6.0
 phoenix1 | device: 2, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:06.0, compute capability: 6.0
 phoenix1 | device: 3, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:07.0, compute capability: 6.0
 phoenix2 | device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0
 phoenix2 | device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:05.0, compute capability: 6.0
 phoenix2 | device: 2, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:06.0, compute capability: 6.0
 phoenix2 | device: 3, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:07.0, compute capability: 6.0
 phoenix3 | device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0
 phoenix3 | device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:05.0, compute capability: 6.0
 phoenix3 | device: 2, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:06.0, compute capability: 6.0
 phoenix3 | device: 3, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:07.0, compute capability: 6.0
 phoenix4 | device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0
 phoenix4 | device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:05.0, compute capability: 6.0
 phoenix4 | device: 2, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:06.0, compute capability: 6.0
 phoenix4 | device: 3, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:07.0, compute capability: 6.0
(20 rows)
</pre>

-# Get GPU configuration as per nvidia-smi:
<pre class="example">
SELECT * FROM madlib.gpu_configuration('nvidia');
</pre>
<pre class="result">
 hostname |                                  gpu_descr
----------+------------------------------------------------------------------------------
 phoenix0 | GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-120672ff-0527-6340-14c1-ac6400103a69)
 phoenix0 | GPU 1: Tesla P100-PCIE-16GB (UUID: GPU-063a5803-a4cb-44b3-818e-b72886b75a7f)
 phoenix0 | GPU 2: Tesla P100-PCIE-16GB (UUID: GPU-a44f8948-f944-ddb9-ea90-e28bc14c176a)
 phoenix0 | GPU 3: Tesla P100-PCIE-16GB (UUID: GPU-11aebd04-b7fe-0a13-b18f-52e41c901956)
 phoenix1 | GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-120672ff-0527-6340-14c1-ac6400103a69)
 phoenix1 | GPU 1: Tesla P100-PCIE-16GB (UUID: GPU-063a5803-a4cb-44b3-818e-b72886b75a7f)
 phoenix1 | GPU 2: Tesla P100-PCIE-16GB (UUID: GPU-a44f8948-f944-ddb9-ea90-e28bc14c176a)
 phoenix1 | GPU 3: Tesla P100-PCIE-16GB (UUID: GPU-11aebd04-b7fe-0a13-b18f-52e41c901956)
 phoenix2 | GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-120672ff-0527-6340-14c1-ac6400103a69)
 phoenix2 | GPU 1: Tesla P100-PCIE-16GB (UUID: GPU-063a5803-a4cb-44b3-818e-b72886b75a7f)
 phoenix2 | GPU 2: Tesla P100-PCIE-16GB (UUID: GPU-a44f8948-f944-ddb9-ea90-e28bc14c176a)
 phoenix2 | GPU 3: Tesla P100-PCIE-16GB (UUID: GPU-11aebd04-b7fe-0a13-b18f-52e41c901956)
 phoenix3 | GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-120672ff-0527-6340-14c1-ac6400103a69)
 phoenix3 | GPU 1: Tesla P100-PCIE-16GB (UUID: GPU-063a5803-a4cb-44b3-818e-b72886b75a7f)
 phoenix3 | GPU 2: Tesla P100-PCIE-16GB (UUID: GPU-a44f8948-f944-ddb9-ea90-e28bc14c176a)
 phoenix3 | GPU 3: Tesla P100-PCIE-16GB (UUID: GPU-11aebd04-b7fe-0a13-b18f-52e41c901956)
 phoenix4 | GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-120672ff-0527-6340-14c1-ac6400103a69)
 phoenix4 | GPU 1: Tesla P100-PCIE-16GB (UUID: GPU-063a5803-a4cb-44b3-818e-b72886b75a7f)
 phoenix4 | GPU 2: Tesla P100-PCIE-16GB (UUID: GPU-a44f8948-f944-ddb9-ea90-e28bc14c176a)
 phoenix4 | GPU 3: Tesla P100-PCIE-16GB (UUID: GPU-11aebd04-b7fe-0a13-b18f-52e41c901956)
(20 rows)
</pre>

-# To get a fuller picture, combine with Greenplum catalog
table gp_segment_configuration which contains information about
segment instance configuration [2].  Here is an example of this table
filtering out master and mirrors:
<pre class="example">
SELECT * FROM gp_segment_configuration WHERE role='p' AND content>=0 ORDER BY hostname, dbid;
</pre>
<pre class="result">
 dbid | content | role | preferred_role | mode | status | port  | hostname | address  | replication_port
------+---------+------+----------------+------+--------+-------+----------+----------+------------------
    2 |       0 | p    | p              | c    | u      | 40000 | phoenix0 | phoenix0 |            70000
    3 |       1 | p    | p              | c    | u      | 40001 | phoenix0 | phoenix0 |            70001
    4 |       2 | p    | p              | c    | u      | 40002 | phoenix0 | phoenix0 |            70002
    5 |       3 | p    | p              | c    | u      | 40003 | phoenix0 | phoenix0 |            70003
    6 |       4 | p    | p              | c    | u      | 40000 | phoenix1 | phoenix1 |            70000
    7 |       5 | p    | p              | c    | u      | 40001 | phoenix1 | phoenix1 |            70001
    8 |       6 | p    | p              | c    | u      | 40002 | phoenix1 | phoenix1 |            70002
    9 |       7 | p    | p              | c    | u      | 40003 | phoenix1 | phoenix1 |            70003
   10 |       8 | p    | p              | c    | u      | 40000 | phoenix2 | phoenix2 |            70000
   11 |       9 | p    | p              | c    | u      | 40001 | phoenix2 | phoenix2 |            70001
   12 |      10 | p    | p              | c    | u      | 40002 | phoenix2 | phoenix2 |            70002
   13 |      11 | p    | p              | c    | u      | 40003 | phoenix2 | phoenix2 |            70003
   14 |      12 | p    | p              | c    | u      | 40000 | phoenix3 | phoenix3 |            70000
   15 |      13 | p    | p              | c    | u      | 40001 | phoenix3 | phoenix3 |            70001
   16 |      14 | p    | p              | c    | u      | 40002 | phoenix3 | phoenix3 |            70002
   17 |      15 | p    | p              | c    | u      | 40003 | phoenix3 | phoenix3 |            70003
   18 |      16 | p    | p              | c    | u      | 40000 | phoenix4 | phoenix4 |            70000
   19 |      17 | p    | p              | c    | u      | 40001 | phoenix4 | phoenix4 |            70001
   20 |      18 | p    | p              | c    | u      | 40002 | phoenix4 | phoenix4 |            70002
   21 |      19 | p    | p              | c    | u      | 40003 | phoenix4 | phoenix4 |            70003
(20 rows)
</pre>
To create a table showing segments with all available
GPU resources:
<pre class="example">
TBD
</pre>
<pre class="result">
TBD
</pre>
To create a table showing segments with a certain type of
GPU resource:
<pre class="example">
TBD
</pre>
<pre class="result">
TBD
</pre>
To create a table limiting the number of segments
on hosts with GPU resource:
<pre class="example">
TBD
</pre>
<pre class="result">
TBD
</pre>

@anchor references
@par References

[1] Nvidia Systems Management Interface (nvidia-smi) https://developer.nvidia.com/nvidia-system-management-interface

[2] Greenplum 'gp_segment_configuration' table https://gpdb.docs.pivotal.io/latest/ref_guide/system_catalogs/gp_segment_configuration.html

@anchor related
@par Related Topics

See madlib_keras_gpu_info.sql_in

*/

CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.gpu_info_tensorflow() RETURNS TEXT[] as
$$
    PythonFunctionBodyOnlyNoSchema(`deep_learning', `madlib_keras_gpu_info')
    return madlib_keras_gpu_info.GPUInfoFunctions.get_gpu_info_from_tensorflow()
$$ LANGUAGE plpythonu IMMUTABLE
m4_ifdef(`__HAS_FUNCTION_PROPERTIES__', `NO SQL', `');

CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.gpu_info_nvidia() RETURNS TEXT[] as
$$
    PythonFunctionBodyOnlyNoSchema(`deep_learning', `madlib_keras_gpu_info')
    return madlib_keras_gpu_info.GPUInfoFunctions.get_gpu_info_from_nvidia()
$$ LANGUAGE plpythonu IMMUTABLE
m4_ifdef(`__HAS_FUNCTION_PROPERTIES__', `NO SQL', `');

CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.gpu_configuration(output_table text, source text)
RETURNS VOID AS
$$
    PythonFunctionBodyOnly(`deep_learning', `madlib_keras_gpu_info')
    from utilities.control import MinWarning
    with AOControl(False) and MinWarning("error"):
        madlib_keras_gpu_info.gpu_configuration(schema_madlib, output_table, source)
$$
LANGUAGE plpythonu
m4_ifdef(`__HAS_FUNCTION_PROPERTIES__', `NO SQL', `');

CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.gpu_configuration(output_table text)
RETURNS VOID AS
$$
    SELECT MADLIB_SCHEMA.gpu_configuration($1, NULL);
$$
LANGUAGE sql;
