# coding=utf-8
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

import plpy
import os

import keras
from keras import backend as K
from keras.layers import *
from keras.models import *
from keras.optimizers import *
import numpy as np

from madlib_keras_helper import expand_input_dims
from madlib_keras_helper import MODEL_DATA_COLNAME
from madlib_keras_wrapper import compile_and_set_weights
from predict_input_params import PredictParamsProcessor
from utilities.model_arch_info import get_input_shape
from utilities.utilities import add_postfix
from utilities.utilities import create_cols_from_array_sql_string
from utilities.utilities import unique_string
from utilities.validate_args import input_tbl_valid
from utilities.validate_args import output_tbl_valid

import madlib_keras_serializer

MODULE_NAME = 'madlib_keras_predict'

def validate_pred_type(pred_type, class_values):
    if not pred_type in ['prob', 'response']:
        plpy.error("{0}: Invalid value for pred_type param ({1}). Must be "\
            "either response or prob.".format(MODULE_NAME, pred_type))
    if pred_type == 'prob' and class_values and len(class_values)+1 >= 1600:
        plpy.error({"{0}: The output will have {1} columns, exceeding the "\
            " max number of columns that can be created (1600)".format(
                MODULE_NAME, len(class_values)+1)})

def _strip_trailing_nulls_from_class_values(class_values):
    """
        class_values is a list of unique class levels in training data. This
        could have multiple Nones in it, and this function strips out all the
        Nones that occur after the first element in the list.
        Examples:
            1) input class_values = ['cat', 'dog']
               output class_values = ['cat', 'dog']

            2) input class_values = [None, 'cat', 'dog']
               output class_values = [None, 'cat', 'dog']

            3) input class_values = [None, 'cat', 'dog', None, None]
               output class_values = [None, 'cat', 'dog']

            4) input class_values = ['cat', 'dog', None, None]
               output class_values = ['cat', 'dog']

            5) input class_values = [None, None]
               output class_values = [None]
        @args:
            @param: class_values, list
        @returns:
            updated class_values list
    """
    num_of_valid_class_values = 0
    if class_values is not None:
        for ele in class_values:
            if ele is None and num_of_valid_class_values > 0:
                break
            num_of_valid_class_values += 1
        # Pass only the valid class_values for creating columns
        class_values = class_values[:num_of_valid_class_values]
    return class_values

def predict(schema_madlib, model_table, test_table, id_col,
            independent_varname, output_table, pred_type, **kwargs):
    # Refactor and add more validation as part of MADLIB-1312.
    input_tbl_valid(model_table, MODULE_NAME)
    input_tbl_valid(test_table, MODULE_NAME)
    output_tbl_valid(output_table, MODULE_NAME)
    param_proc = PredictParamsProcessor(model_table, MODULE_NAME)

    class_values = param_proc.get_class_values()
    compile_params = param_proc.get_compile_params()
    dependent_varname = param_proc.get_dependent_varname()
    dependent_vartype = param_proc.get_dependent_vartype()
    model_data = param_proc.get_model_data()
    model_arch = param_proc.get_model_arch()
    normalizing_const = param_proc.get_normalizing_const()
    # TODO: Validate input shape as part of MADLIB-1312
    input_shape = get_input_shape(model_arch)
    compile_params = "$madlib$" + compile_params + "$madlib$"

    validate_pred_type(pred_type, class_values)
    is_response = True if pred_type == 'response' else False
    intermediate_col = unique_string()
    if is_response:
        pred_col_name = add_postfix("estimated_", dependent_varname)
        pred_col_type = dependent_vartype
    else:
        pred_col_name = "prob"
        pred_col_type = 'double precision'

    class_values = _strip_trailing_nulls_from_class_values(class_values)

    prediction_select_clause = create_cols_from_array_sql_string(
        class_values, intermediate_col, pred_col_name,
        pred_col_type, is_response, MODULE_NAME)

    plpy.execute("""
        CREATE TABLE {output_table} AS
        SELECT {id_col}, {prediction_select_clause}
        FROM (
            SELECT {test_table}.{id_col},
                   ({schema_madlib}.internal_keras_predict
                       ({independent_varname},
                        $MAD${model_arch}$MAD$,
                        {0},
                        ARRAY{input_shape},
                        {compile_params},
                        {is_response},
                        {normalizing_const})
                   ) AS {intermediate_col}
        FROM {test_table}, {model_table}
        ) q
        """.format(MODEL_DATA_COLNAME, **locals()))

def internal_keras_predict(x_test, model_arch, model_data, input_shape,
                           compile_params, is_response, normalizing_const):
    model = model_from_json(model_arch)
    device_name = '/cpu:0'
    os.environ["CUDA_VISIBLE_DEVICES"] = '-1'
    model_shapes = madlib_keras_serializer.get_model_shapes(model)
    compile_and_set_weights(model, compile_params, device_name,
                            model_data, model_shapes)
    # Since the test data isn't mini-batched,
    # we have to make sure that the test data np array has the same
    # number of dimensions as input_shape. So we add a dimension to x.
    x_test = expand_input_dims(x_test, target_type='float32')
    x_test /= normalizing_const
    if is_response:
        proba_argmax = model.predict_classes(x_test)
        # proba_argmax is a list with exactly one element in it. That element
        # refers to the index containing the largest probability value in the
        # output of Keras' predict function.
        return proba_argmax
    else:
        probs = model.predict_proba(x_test)
        # probs is a list containing a list of probability values, of all
        # class levels. Since we are assuming each input is a single image,
        # and not mini-batched, this list contains exactly one list in it,
        # so return back the first list in probs.
        return probs[0]
